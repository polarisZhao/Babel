### 1. 数据预处理

##### 中心化

中心化是预处理最常用的形式。**在实践中，对数据中每个特征(图像中的每个像素可以看做一种特征)减去平均值来中心化**．从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。**对于图像而言，更常用的是计算训练集图像像素均值，之后处理训练集/验证集和测试集图像时需要分别减去该均值．**

##### 标准化

标准化是指使数据的所有维度的数值范围都近似相等。有两种常用方法可以实现标准化:

**z-score 标准化**：先对数据做零中心化处理(减去均值)，然后每个维度都除以其标准差．
$$
x^\prime = \frac{x-\bar{x}}{\sigma}
$$
**归一化**:  对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。 
$$
x^\prime = \frac{x-x_{mean}}{x_{max} - x_{min}}
$$
这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。**在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。**



### 2. 网络参数初始化

##### 1. 全零初始化

​        全零初始化会导致网络不通神经元的输出相同，相同的输出导致梯度更新完全一样，这样便会令更新后的参数仍然保持一样的状态，从而无法对模型进行训练。

##### 2. 随机初始化

​        将参数值随机设定为接近0的一个很小的随机数（有正有负）,　在实践中，　参数服从高斯分布或者均匀分布都是较有效的初始化方式．

**高斯分布**：

设输入神经元的个数为$n_{in}$，　输出神经元的个数为$n_{out}$.　则服从高斯分布的参数随机初始化为:

~~~python
# origin method
w = 0.001 * randn(n_in, n_out)
# Xavier method 
w = (0.001 * randn(n_in, n_out)) / sqrt(n)
# He method
w = (0.001 * randn(n_in, n_out)) / sqrt(n/2)
~~~

其中 0.001为控制参数量纲的因子．n为输入神经元的个数$n_{in}$ ,有时也可指定为 $(n_{in}+n_{out})/2$

**均匀分布**：

设输入神经元的个数为$n_{in}$，输出神经元的个数为$n_{out}$.　则服从均匀的参数随机初始化为:

~~~python
#  Xavier method
low = -sqrt(3/n)
high = sqrt(3/n)
w = 0.001 * (low + (high - low) * rand(n_in, n_out))
# He mothod
low = -sqrt(6/n)
high = sqrt(6/n)
w = 0.001 * (low + (high - low) * rand(n_in, n_out))
~~~

##### 3. 预训练模型初始化

除了直接随机初始化网络参数，一种简单易行且十分有效的方式则是利用预训练模型(pre-trained model)－－将预训练模型的参数作为新任务的初始化参数.

##### 4. 数据敏感的参数初始化方式

2016年美国加州伯克利分校和卡内基梅隆大学提出的一种基于数据敏感的参数初始化方式，是一种根据自身任务数据集量身定制的参数初始化方式，　其代码链接为:  [github address](https://github.com/philkr/magic_init)



##### 总结 

- **网络参数初始化的优劣在极大程度上决定了网络的最终性能**。
- **比较推荐的网络初始化方式为 He 方式，将参数初始化为服从高斯部分或者均匀分布的较小随机数，同时对参数方差需要加以规范化**。
- 另外借助预训练模型中的参数作为新任务的参数初始化方式一种简便且十分有效的模型参数初始化方法。



Xavier 参数初始化方式的由来：

假设s为未经非线性变化的该层网络输出结果，w为该层参数，x为该层的输入数据，则：
$$
\begin{array} \d
Var(s) &= Var(\sum\limits_i^nw_i x_i)   \\
       &= \sum\limits_i^n Var(w_i x_i)   \\
       &= \sum\limits_i^n [E(w_i)]^2Var(x_i) +[E(x_i)]^2Var(w_i) + Var(x_i)Var(x_i)     \\
       &= \sum\limits_i^n Var(x_i)Var(w_i) \\
       &= (nVar(w))Var(x) \\
\end{array}
$$
为了保证输出数据 $Var(s)$ 和输入数据 $Var(x)$ 的方差一致，需令 $nVar（w）=1$，即 $n \cdot Var(a\omega)=n\cdot a^2 \cdot Var(\omega') = 1$， 则 $a=\sqrt{(1/n)}$， 其中 $\omega'$为方差规范化后的参数。






